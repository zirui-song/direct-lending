{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d4ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract deal size, interest rate, maturity date\n",
    "import openai\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "# set up openai \n",
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output from OpenAI: ```\n",
      "Deal Amount: $8,000,000\n",
      "Interest Spread: Not specified\n",
      "Maturity: Not specified\n",
      "```\n",
      "Row 0: deal_amount=$8,000,000, interest_spread=Not specified, maturity=Not specified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zrsong/Dropbox (MIT)/Research Projects/Direct Lending/Code/Credit_agreement.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W1sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m output_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../Data/Intermediate/loancontracts_with_extracted_dealinfo.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W1sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39m# Process the DataFrame\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W1sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m df_with_extracted_info \u001b[39m=\u001b[39m process_dataframe(df, text_column, output_file)\n",
      "\u001b[1;32m/Users/zrsong/Dropbox (MIT)/Research Projects/Direct Lending/Code/Credit_agreement.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W1sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m     \u001b[39m# Save the results periodically to avoid data loss\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W1sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# Save every 10 rows\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W1sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m         df_with_extracted_info\u001b[39m.\u001b[39;49mto_csv(output_file, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W1sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m \u001b[39m# Final save after all rows are processed\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W1sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m df_with_extracted_info\u001b[39m.\u001b[39mto_csv(output_file, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3953\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3955\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3956\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3957\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3961\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3962\u001b[0m )\n\u001b[0;32m-> 3964\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3965\u001b[0m     path_or_buf,\n\u001b[1;32m   3966\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3967\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3968\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3969\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3970\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3971\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3972\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3973\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3974\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3975\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3976\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3977\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3978\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3979\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3980\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3981\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_body()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m start_i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_chunk(start_i, end_i)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/formats/csvs.py:324\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    321\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(res\u001b[39m.\u001b[39m_iter_column_arrays())\n\u001b[1;32m    323\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_index[slicer]\u001b[39m.\u001b[39m_get_values_for_csv(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[0;32m--> 324\u001b[0m libwriters\u001b[39m.\u001b[39;49mwrite_csv_rows(\n\u001b[1;32m    325\u001b[0m     data,\n\u001b[1;32m    326\u001b[0m     ix,\n\u001b[1;32m    327\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnlevels,\n\u001b[1;32m    328\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcols,\n\u001b[1;32m    329\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwriter,\n\u001b[1;32m    330\u001b[0m )\n",
      "File \u001b[0;32mwriters.pyx:73\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the model's maximum token limit\n",
    "MAX_TOKENS = 128000 - 150  # Subtracting an additional buffer for safety\n",
    "\n",
    "# Load the tokenizer for the model you are using (gpt-3.5-turbo or gpt-4)\n",
    "tokenizer = tiktoken.encoding_for_model('gpt-4')  # Adjust model name if using a different one\n",
    "\n",
    "# Function to count tokens accurately using the tokenizer\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Function to truncate the text so it fits within the token limit\n",
    "def truncate_text(text, max_tokens):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    if len(encoded) > max_tokens:\n",
    "        truncated_encoded = encoded[:max_tokens]\n",
    "        return tokenizer.decode(truncated_encoded)  # Decode back into text\n",
    "    return text\n",
    "\n",
    "def extract_deal_info(text):\n",
    "    # Accurately truncate the text to fit within the token limit\n",
    "    truncated_text = truncate_text(text, MAX_TOKENS)\n",
    "\n",
    "    # Define the prompt to extract borrower and lender\n",
    "    prompt = f\"\"\"\n",
    "\"You are a financial analyst, and your task is to extract key financial terms from a credit agreement document. The specific details you need to identify are:\n",
    "\n",
    "Deal Size (Amount): The total loan or credit amount provided in the agreement, typically expressed in US dollars (e.g., \"$100 million\" or \"$250,000,000\"). \n",
    "You should make sure that the amount is clearly stated in dollars $. If the amount is not explicitly stated in dollars, please convert it to dollars.\n",
    "\n",
    "Interest Spread (Rate): The applicable rate or margin for the loan, which is often stated as a spread over a benchmark rate (e.g., LIBOR, SOFR), such as 'LIBOR + 2%' or 'SOFR + 1.5%'. In such case, report LIBOR + 2% or SOFR + 1.5% for instance.\n",
    "A few more examples include: \n",
    "1. “Applicable Rate” means, for any day, (i) 4.50% per annum, in the case of an ABR Loan or (ii) 5.50% per annum, in the case of a Eurodollar Loan. In this case, you should report LIBOR + 5.50%. \n",
    "2. Interest on Loans.  Subject to the provisions of Section 2.07, the Loans shall bear interest (computed on the basis of the actual number of days elapsed over a year of 360 days) at a rate per annum equal to 9.00% on the unpaid principal amount thereof through the date such Loan is paid in full in cash (whether upon final maturity, prepayment, acceleration or otherwise). In this case, you should report 9.00%.\n",
    "\n",
    "Maturity Date: The date by which the loan must be repaid, typically presented as a specific date (e.g., 'December 31, 2025') or a period (e.g., '5 years from the effective date').\n",
    "A few more examples include: \n",
    "1. “Term Maturity Date” means (i) September 1, 2027 (or if such day is not a Business Day, the immediately preceding Business Day) or ... In this case, you should report September 1, 2027.\n",
    "2. “Delayed Draw Term B Loan Maturity Date” shall mean May 24, 2016. In this case, you should report May 24, 2016.\n",
    "\n",
    "From the document provided below, please extract the deal size, interest spread, and maturity date in a clear and structured format. If any of these details are missing, please note that as well.\n",
    "\n",
    "Text:\n",
    "{truncated_text}\n",
    "\n",
    "Please format the output as follows (on separate lines): \\n\"\n",
    "\"Deal Amount: <value>\n",
    " Interest Spread: <value>\n",
    " Maturity: <value>\"\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model='gpt-4o-mini',  # Ensure you're using the correct model\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=150,  # Increase max tokens for larger output\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "         # Extract the response from ChatGPT\n",
    "        result = response['choices'][0]['message']['content']\n",
    "        # Debugging: Print the raw output for inspection\n",
    "        print(\"Raw output from OpenAI:\", result)\n",
    "\n",
    "        # Parse the result to extract deal amount, interest spread, and maturity\n",
    "        deal_amount = None\n",
    "        interest_spread = None\n",
    "        maturity = None\n",
    "\n",
    "        # Look for specific phrases in the response to extract the values\n",
    "        for line in result.split(\"\\n\"):\n",
    "            if \"Deal Amount:\" in line:\n",
    "                deal_amount = line.split(\"Deal Amount:\")[-1].strip()\n",
    "            elif \"Interest Spread:\" in line:\n",
    "                interest_spread = line.split(\"Interest Spread:\")[-1].strip()\n",
    "            elif \"Maturity:\" in line:\n",
    "                maturity = line.split(\"Maturity:\")[-1].strip()\n",
    "\n",
    "        return deal_amount, interest_spread, maturity\n",
    "\n",
    "    except openai.error.RateLimitError:\n",
    "        print(\"Rate limit exceeded. Waiting for 60 seconds...\")\n",
    "        time.sleep(60)  # Wait for 60 seconds (or the appropriate time based on rate limits)\n",
    "        return extract_deal_info(prompt)\n",
    "\n",
    "# Function to process the DataFrame row by row and update the results constantly\n",
    "def process_dataframe(df, text_column, output_file):\n",
    "    # Load the previous state of the DataFrame if it exists (to append results)\n",
    "    if os.path.exists(output_file):\n",
    "        df_with_extracted_info = pd.read_csv(output_file)\n",
    "    else:\n",
    "        df_with_extracted_info = df.copy()\n",
    "\n",
    "    # Only process rows where deal_amount is not yet extracted\n",
    "    for index, row in df.iterrows():\n",
    "        # Check if this row has already been processed\n",
    "        if index in df_with_extracted_info.index and pd.notna(df_with_extracted_info.at[index, 'deal_amount']):\n",
    "            continue\n",
    "        \n",
    "        # Extract information\n",
    "        deal_amount, interest_spread, maturity = extract_deal_info(row[text_column])\n",
    "        \n",
    "        # Check if the extraction function is returning valid results\n",
    "        print(f\"Row {index}: deal_amount={deal_amount}, interest_spread={interest_spread}, maturity={maturity}\")\n",
    "        \n",
    "        # Update the DataFrame with the extracted information\n",
    "        df_with_extracted_info.at[index, 'deal_amount'] = deal_amount\n",
    "        df_with_extracted_info.at[index, 'interest_spread'] = interest_spread\n",
    "        df_with_extracted_info.at[index, 'maturity'] = maturity\n",
    "        \n",
    "        # Save the results periodically to avoid data loss\n",
    "        if index % 10 == 0:  # Save every 10 rows\n",
    "            df_with_extracted_info.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Final save after all rows are processed\n",
    "    df_with_extracted_info.to_csv(output_file, index=False)\n",
    "    return df_with_extracted_info\n",
    "\n",
    "# Example usage: Processing a DataFrame with text data\n",
    "df = pd.read_csv('../Data/LoansFull/cleaned_loancontracts.csv')  # Load your CSV file\n",
    "# generate deal_amount, interest_spread, maturity columns\n",
    "df['deal_amount'] = None\n",
    "df['interest_spread'] = None\n",
    "df['maturity'] = None\n",
    "\n",
    "# Specify the text column containing the deal information\n",
    "text_column = 'text'  # Replace with the actual name of your text column\n",
    "\n",
    "# Define output file path\n",
    "output_file = '../Data/Intermediate/loancontracts_with_extracted_dealinfo.csv'\n",
    "\n",
    "# Process the DataFrame\n",
    "df_with_extracted_info = process_dataframe(df, text_column, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/zrsong/Dropbox (MIT)/Research Projects/Direct Lending/Code/Credit_agreement.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W5sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df_with_extracted_info\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W5sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# Example usage: Processing a DataFrame with text data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W5sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../Data/LoansFull/cleaned_loancontracts.csv\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Load your CSV file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W5sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m# generate deal_amount, interest_spread, maturity columns\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Credit_agreement.ipynb#W5sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mborrower_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Tokenizing the text to get the first 1000 tokens\n",
    "def get_first_1000_tokens(text):\n",
    "    tokens = text.split()  # Split the text by spaces to approximate tokens\n",
    "    return ' '.join(tokens[:1000])  # Join back the first 1000 tokens\n",
    "\n",
    "def extract_deal_info(text):\n",
    "     # Limit text to first 1000 tokens\n",
    "    text = get_first_1000_tokens(text)\n",
    "    # Define the prompt to extract borrower and lender\n",
    "    prompt = f\"\"\"\n",
    "You are an AI language model designed to extract specific information from legal documents. Please read the following company's credit agreement and extract the following details:\n",
    "\n",
    "1. **Borrower Name:**\n",
    "2. **Lender Name (Lead Arrangers):**\n",
    "\n",
    "Please first search for lead arrangers. If you cannot find the lead arrangers, then serach for administrative agents. Don't include in your answers the following: \n",
    "\"various lenders,\" \"various financial institutions,\" \"certain financial institutions,\" \"lenders from time to time party hereto,\" as those are not lender names\n",
    "If the information in nowhere to be found in all exhibits, return \"Not Found\". \n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Please format the output as follows (on separate lines): \\n\"\n",
    "\"Borrower Name: <value>\n",
    " Lender Name: <value>\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model='gpt-4o-mini',  # Ensure you're using the correct model\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=500,  # Increase max tokens for larger output\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "         # Extract the response from ChatGPT\n",
    "        result = response['choices'][0]['message']['content']\n",
    "        # Debugging: Print the raw output for inspection\n",
    "        print(\"Raw output from OpenAI:\", result)\n",
    "\n",
    "        # Parse the result to extract deal amount, interest spread, and maturity\n",
    "        deal_amount = None\n",
    "        interest_spread = None\n",
    "        maturity = None\n",
    "\n",
    "        # Look for specific phrases in the response to extract the values\n",
    "        for line in result.split(\"\\n\"):\n",
    "            if \"Borrower Name:\" in line:\n",
    "                borrower_name = line.split(\"Borrower Name:\")[-1].strip()\n",
    "            elif \"Lender Name:\" in line:\n",
    "                lender_name = line.split(\"Lender Name:\")[-1].strip()\n",
    "\n",
    "        return borrower_name, lender_name\n",
    "\n",
    "    except openai.error.RateLimitError:\n",
    "        print(\"Rate limit exceeded. Waiting for 60 seconds...\")\n",
    "        time.sleep(60)  # Wait for 60 seconds (or the appropriate time based on rate limits)\n",
    "        return extract_deal_info(prompt)\n",
    "\n",
    "# Function to process the DataFrame row by row and update the results constantly\n",
    "def process_dataframe(df, text_column, output_file):\n",
    "    # Load the previous state of the DataFrame if it exists (to append results)\n",
    "    if os.path.exists(output_file):\n",
    "        df_with_extracted_info = pd.read_csv(output_file)\n",
    "    else:\n",
    "        df_with_extracted_info = df.copy()\n",
    "\n",
    "    # Only process rows where deal_amount is not yet extracted\n",
    "    for index, row in df.iterrows():\n",
    "        # Check if this row has already been processed\n",
    "        if index in df_with_extracted_info.index and pd.notna(df_with_extracted_info.at[index, 'borrower_name']):\n",
    "            continue\n",
    "        \n",
    "        # Extract information\n",
    "        borrower_name, lender_name = extract_deal_info(row[text_column])\n",
    "        \n",
    "        # Check if the extraction function is returning valid results\n",
    "        print(f\"Row {index}: borrower_name={borrower_name}, lender_name={lender_name}\")\n",
    "        \n",
    "        # Update the DataFrame with the extracted information\n",
    "        df_with_extracted_info.at[index, 'borrower_name'] = borrower_name\n",
    "        df_with_extracted_info.at[index, 'lender_name'] = lender_name\n",
    "        \n",
    "        # Save the results periodically to avoid data loss\n",
    "        if index % 500 == 0:  # Save every 500 rows\n",
    "            df_with_extracted_info.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Final save after all rows are processed\n",
    "    df_with_extracted_info.to_csv(output_file, index=False)\n",
    "    return df_with_extracted_info\n",
    "\n",
    "# Example usage: Processing a DataFrame with text data\n",
    "df = pd.read_csv('../Data/LoansFull/cleaned_loancontracts.csv')  # Load your CSV file\n",
    "# generate deal_amount, interest_spread, maturity columns\n",
    "df['borrower_name'] = None\n",
    "df['lender_name'] = None\n",
    "\n",
    "# Specify the text column containing the deal information\n",
    "text_column = 'text'  # Replace with the actual name of your text column\n",
    "\n",
    "# Define output file path\n",
    "output_file = '../Data/Intermediate/loancontracts_with_extracted_lendernames.csv'\n",
    "\n",
    "# Process the DataFrame\n",
    "df_with_extracted_info = process_dataframe(df, text_column, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
