{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory is set to: /Users/zrsong/Dropbox (MIT)/Research Projects/Direct Lending/Code\n",
      "Loading library list...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Use S&P ratings data as Compustat ratings data were discontinued in 2017\\n# Query the S&P ratings data\\nquery = f\"\"\"\\n    SELECT gvkey, ratingdate, ratingsymbol\\n    FROM ciq_ratings.wrds_erating \\n    WHERE ratingdate >= \\'{start_date}\\' AND ratingdate <= \\'{end_date}\\'\\n\"\"\"\\n\\n# Execute the query and fetch the data\\nratings_date = db.raw_sql(query)\\n\\n# Save the data to a CSV file\\nratings_date.to_csv(\\'../Data/ratings_data.csv\\', index=False)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# Set the working directory to the current script's directory (which in this case is already the working directory)\n",
    "os.chdir(script_dir)\n",
    "\n",
    "print(f\"Working directory is set to: {script_dir}\")\n",
    "\n",
    "# Connect to WRDS\n",
    "db = wrds.Connection(wrds_username='zrsong')\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '1994-01-01'\n",
    "end_date = '2024-06-30'\n",
    "\n",
    "'''\n",
    "# Use S&P ratings data as Compustat ratings data were discontinued in 2017\n",
    "# Query the S&P ratings data\n",
    "query = f\"\"\"\n",
    "    SELECT gvkey, ratingdate, ratingsymbol\n",
    "    FROM ciq_ratings.wrds_erating \n",
    "    WHERE ratingdate >= '{start_date}' AND ratingdate <= '{end_date}'\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the data\n",
    "ratings_date = db.raw_sql(query)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "ratings_date.to_csv('../Data/ratings_data.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aco_amda', 'aco_imda', 'aco_indfnta', 'aco_indfntq', 'aco_indfntytd', 'aco_indsta', 'aco_indstq', 'aco_indstytd', 'aco_notesa', 'aco_notesq', 'aco_notessa', 'aco_notesytd', 'aco_pnfnda', 'aco_pnfndq', 'aco_pnfndytd', 'aco_pnfnta', 'aco_pnfntq', 'aco_pnfntytd', 'aco_transa', 'aco_transq', 'aco_transsa', 'aco_transytd', 'adsprate', 'asec_amda', 'asec_imda', 'asec_notesa', 'asec_notesq', 'asec_transa', 'asec_transq', 'chars', 'co_aacctchg', 'co_aaudit', 'co_adesind', 'co_adjfact', 'co_afnd1', 'co_afnd2', 'co_afnddc1', 'co_afnddc2', 'co_afntind1', 'co_afntind2', 'co_ainvval', 'co_amkt', 'co_busdescl', 'co_cotype', 'co_filedate', 'co_fortune', 'co_hgic', 'co_iacctchg', 'co_iaudit', 'co_idesind', 'co_ifndq', 'co_ifndsa', 'co_ifndytd', 'co_ifntq', 'co_ifntsa', 'co_ifntytd', 'co_imkt', 'co_industry', 'co_ipcd', 'co_mthly', 'co_offtitl', 'company', 'currency', 'dd_group', 'dd_group_xref', 'dd_item', 'dd_package', 'ecind_desc', 'ecind_mth', 'exrt_dly', 'exrt_mth', 'funda', 'funda_fncd', 'fundq', 'fundq_fncd', 'idx_ann', 'idx_anndes', 'idx_daily', 'idx_index', 'idx_mth', 'idx_qrt', 'idx_qrtdes', 'idxcst_his', 'io_qaggregate', 'io_qbuysell', 'io_qchanges', 'io_qfloatadj', 'io_qholders', 'it_mbuysell', 'it_msummary', 'it_r_rltn', 'names', 'names_aco_indsta', 'names_aco_indstq', 'names_aco_pnfnda', 'names_aco_pnfndq', 'names_adsprate', 'names_ix', 'names_ix_cst', 'names_seg', 'namesd', 'namesm', 'namesq', 'r_accstd', 'r_acqmeth', 'r_auditors', 'r_auopic', 'r_balpres', 'r_cf_formt', 'r_co_status', 'r_coindpre', 'r_compstat', 'r_consol', 'r_country', 'r_cstclscd', 'r_datacode', 'r_datafmt', 'r_divtaxmarker', 'r_docsrce', 'r_ex_codes', 'r_exchgtier', 'r_exrt_typ', 'r_fndfntcd', 'r_footnts', 'r_foricd', 'r_giccd', 'r_hcalendr', 'r_idxclscd', 'r_inactvcd', 'r_incstats', 'r_indfmt', 'r_indsec', 'r_invval', 'r_issuetyp', 'r_majidxcl', 'r_mic_codes', 'r_naiccd', 'r_notetype', 'r_ntsubtype', 'r_offcrso', 'r_ogmethod', 'r_opinions', 'r_prc_stat', 'r_qsrcdoc', 'r_sec_stat', 'r_secannfn', 'r_sectors', 'r_siccd', 'r_spiicd', 'r_spmicd', 'r_statalrt', 'r_states', 'r_stko', 'r_titles', 'r_updates', 'sec_adesind', 'sec_adjfact', 'sec_afnd', 'sec_afnddc', 'sec_afnt', 'sec_divid', 'sec_dprc', 'sec_dtrt', 'sec_history', 'sec_idcurrent', 'sec_idesind', 'sec_idhist', 'sec_ifnd', 'sec_ifnt', 'sec_mdivfn', 'sec_mshare', 'sec_msptfn', 'sec_mth', 'sec_mthdiv', 'sec_mthprc', 'sec_mthspt', 'sec_mthtrt', 'sec_shortint', 'sec_spind', 'sec_split', 'secd', 'secm', 'security', 'sedolgvkey', 'seg_ann', 'seg_annfund', 'seg_customer', 'seg_geo', 'seg_naics', 'seg_product', 'seg_type', 'spidx_cst', 'spind', 'spind_dly', 'spind_mth', 'wrds_ratios', 'wrds_seg_customer', 'wrds_seg_geo', 'wrds_seg_product', 'wrds_segmerged', 'xfl_column', 'xfl_table']\n"
     ]
    }
   ],
   "source": [
    "# show available libraries from wrds\n",
    "libraries = db.list_libraries()\n",
    "\n",
    "# show available tables from wrds\n",
    "tables = db.list_tables(library='comp_na_daily_all')\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) could not receive data from server: Operation timed out\nSSL SYSCALL error: Operation timed out\n\n[SQL: \n    SELECT *\n    FROM comp_na_daily_all.funda\n    WHERE datadate >= '1994-01-01' AND datadate <= '2024-06-30'\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1970\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1969\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1970\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1971\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1972\u001b[0m         )\n\u001b[1;32m   1974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 924\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not receive data from server: Operation timed out\nSSL SYSCALL error: Operation timed out\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/zrsong/Dropbox (MIT)/Research Projects/Direct Lending/Code/Download_WRDS_Data.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Download_WRDS_Data.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# use the varlist above to query quarterly compustat data (don't use join(varlist) as it will return a string)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Download_WRDS_Data.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Download_WRDS_Data.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    SELECT *\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Download_WRDS_Data.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m    FROM comp_na_daily_all.\u001b[39m\u001b[39m{\u001b[39;00mfund_table\u001b[39m}\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Download_WRDS_Data.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m    WHERE datadate >= \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mstart_date\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m AND datadate <= \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mend_date\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Download_WRDS_Data.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zrsong/Dropbox%20%28MIT%29/Research%20Projects/Direct%20Lending/Code/Download_WRDS_Data.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m compa \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39;49mraw_sql(query)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/wrds/sql.py:566\u001b[0m, in \u001b[0;36mConnection.raw_sql\u001b[0;34m(self, sql, coerce_float, date_cols, index_col, params, chunksize, return_iter)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39mQueries the database using a raw SQL string.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39m    2003-09-10  09:35:20.709000  N       AA       None     None  108100.0  28.200          N      00  1.929947e+15         C  None\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql_query(\n\u001b[1;32m    567\u001b[0m         sql,\n\u001b[1;32m    568\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection,\n\u001b[1;32m    569\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    570\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mdate_cols,\n\u001b[1;32m    571\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    572\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    573\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    574\u001b[0m     )\n\u001b[1;32m    575\u001b[0m     \u001b[39mif\u001b[39;00m return_iter \u001b[39mor\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m         \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39massert\u001b[39;00m dtype_backend \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[39mwith\u001b[39;00m pandasSQL_builder(con) \u001b[39mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    527\u001b[0m         sql,\n\u001b[1;32m    528\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    529\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    530\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    531\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    532\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    533\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    534\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m    535\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/sql.py:1836\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[1;32m   1780\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1781\u001b[0m     sql: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1788\u001b[0m     dtype_backend: DtypeBackend \u001b[39m|\u001b[39m Literal[\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1789\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m   1790\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m \u001b[39m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1834\u001b[0m \n\u001b[1;32m   1835\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1836\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(sql, params)\n\u001b[1;32m   1837\u001b[0m     columns \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m   1839\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/sql.py:1659\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   1657\u001b[0m args \u001b[39m=\u001b[39m [] \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m [params]\n\u001b[1;32m   1658\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(sql, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> 1659\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcon\u001b[39m.\u001b[39;49mexec_driver_sql(sql, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1660\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon\u001b[39m.\u001b[39mexecute(sql, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1782\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1777\u001b[0m execution_options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execution_options\u001b[39m.\u001b[39mmerge_with(\n\u001b[1;32m   1778\u001b[0m     execution_options\n\u001b[1;32m   1779\u001b[0m )\n\u001b[1;32m   1781\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[0;32m-> 1782\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1783\u001b[0m     dialect,\n\u001b[1;32m   1784\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_statement,\n\u001b[1;32m   1785\u001b[0m     statement,\n\u001b[1;32m   1786\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1787\u001b[0m     execution_options,\n\u001b[1;32m   1788\u001b[0m     statement,\n\u001b[1;32m   1789\u001b[0m     distilled_parameters,\n\u001b[1;32m   1790\u001b[0m )\n\u001b[1;32m   1792\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1849\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1847\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1849\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[1;32m   1850\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1851\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1989\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1986\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1988\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1989\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1990\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1991\u001b[0m     )\n\u001b[1;32m   1993\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2356\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2355\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2356\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   2357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2358\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1970\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1968\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1970\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1971\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1972\u001b[0m         )\n\u001b[1;32m   1974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1975\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1976\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1977\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1982\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 924\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) could not receive data from server: Operation timed out\nSSL SYSCALL error: Operation timed out\n\n[SQL: \n    SELECT *\n    FROM comp_na_daily_all.funda\n    WHERE datadate >= '1994-01-01' AND datadate <= '2024-06-30'\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "# Annual Compustat data\n",
    "fund_table = 'funda'\n",
    "# use the varlist above to query quarterly compustat data (don't use join(varlist) as it will return a string)\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM comp_na_daily_all.{fund_table}\n",
    "    WHERE datadate >= '{start_date}' AND datadate <= '{end_date}'\n",
    "\"\"\"\n",
    "compa = db.raw_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all colnames of compa\n",
    "# check if sic exists\n",
    "# for each gvkey fyear, keep the one with the highest at\n",
    "compa = compa.sort_values(['gvkey', 'fyear', 'at'], ascending=[True, True, False])\n",
    "compa = compa.drop_duplicates(subset=['gvkey', 'fyear'], keep='first')\n",
    "# output csv. format\n",
    "compa.to_csv(\"../Data/Raw/compustat_annual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quarterly Compustat data\n",
    "fund_table = 'fundq'\n",
    "varlist = ['gvkey', 'conm', 'tic', 'cusip','fyearq', 'fqtr', 'fyr', 'atq','capxy', 'ceqq', 'cogsq', \n",
    "           'cshoq', 'dlcq', 'dlcchy','dlttq', 'dpq', 'ibq', 'itccy', 'fic', 'pstkrq',\n",
    "           'ltq', 'mibq', 'niq', 'prstkccy', 'pstkq', 'req', 'revtq', 'saleq',\n",
    "           'seqq', 'txdbq', 'txdiq', 'txditcq', 'wcapchy', 'xinty', 'xrdq', 'xrdy', 'xsgaq',\n",
    "           'mkvaltq', 'epspxq', 'epsfxq', 'ajexq', 'prccq', 'oancfy', 'ivncfy', 'rdq', 'ppegtq', 'ppentq']\n",
    "# Join the list into a comma-separated string\n",
    "varlist_str = \", \".join(varlist)\n",
    "# use the varlist above to query quarterly compustat data (don't use join(varlist) as it will return a string)\n",
    "query = f\"\"\"\n",
    "    SELECT {varlist_str}\n",
    "    FROM comp_na_daily_all.{fund_table}\n",
    "    WHERE datadate >= '{start_date}' AND datadate <= '{end_date}'\n",
    "\"\"\"\n",
    "compq = db.raw_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2006, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,\n",
       "       2003, 2004, 2005, 2007, 2008, 2010, 2009, 2016, 2017, 2011, 2012,\n",
       "       2013, 2014, 2015, 2018, 2019, 2020, 2021, 2022, 2023, 2024])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for years in the data\n",
    "compq['fyearq'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to deal with duplicates? Keep last available entry (datadate)\n",
    "compq.dropna(subset=['fyearq', 'fqtr'], inplace=True)\n",
    "compq.sort_values(['gvkey','fyearq', 'fqtr', 'atq'], inplace=True)\n",
    "compq = compq[~compq.duplicated(['gvkey', 'fyearq', 'fqtr'], keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate columns: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "duplicate_columns = compq.columns[compq.columns.duplicated()]\n",
    "print(\"Duplicate columns:\", duplicate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/pgdf58ms1yd3ch8xjn9fmpmm0000gq/T/ipykernel_35699/4278593784.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  compq['se'].fillna((compq['ceqq'] + compq['pstkq']), inplace=True)\n",
      "/var/folders/n2/pgdf58ms1yd3ch8xjn9fmpmm0000gq/T/ipykernel_35699/4278593784.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  compq['se'].fillna((compq['atq'] - compq['ltq'] + compq['mibq'].fillna(0)), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Calculating BE\n",
    "# Shareholder Equity\n",
    "compq['se'] = compq['seqq']\n",
    "# Uses Common Equity (ceq) + Preferred Stock (pstk) if SEQ is missing:\n",
    "compq['se'].fillna((compq['ceqq'] + compq['pstkq']), inplace=True)\n",
    "# Uses Total Assets (at) - Liabilities (lt) + Minority Interest (mib, if available), if others are missing\n",
    "compq['se'].fillna((compq['atq'] - compq['ltq'] + compq['mibq'].fillna(0)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/pgdf58ms1yd3ch8xjn9fmpmm0000gq/T/ipykernel_35699/4121065189.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  compq['ps'].fillna(compq['pstkq'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Preferred Stock\n",
    "# Preferred Stock (Redemption Value)\n",
    "compq['ps'] = compq['pstkrq']\n",
    "# Uses Preferred Stock (Liquidating Value (pstkl)) if Preferred Stock (Redemption Value) is missing (pstkl doesnt' exist for quarterly data)\n",
    "# compq['ps'].fillna(compq['pstkl'], inplace=True)\n",
    "# Uses Preferred Stock (Carrying Value (pstk)) if others are missing\n",
    "compq['ps'].fillna(compq['pstkq'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/pgdf58ms1yd3ch8xjn9fmpmm0000gq/T/ipykernel_35699/1696288597.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  compq['dt'].fillna(compq['txdbq'].fillna(0), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Deferred Taxes\n",
    "# Uses Deferred Taxes and Investment Tax Credit (txditc)\n",
    "compq['dt'] = compq['txditcq']\n",
    "# This was Novy-Marx old legacy code. We drop this part to be in accordance with Ken French.\n",
    "# Uses Deferred Taxes and Investment Tax Credit(txdb) + Investment Tax Credit (Balance Sheet) (itcb) if txditc is missing (itcb (Investment Tax Credit (Balance Sheet)) doesn't exist for quarterly data)\n",
    "compq['dt'].fillna(compq['txdbq'].fillna(0), inplace=True)\n",
    "# If all measures are missing, set to missing\n",
    "compq.loc[pd.isnull(compq['txditcq']) & pd.isnull(compq['txdbq']), 'dt'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book Equity\n",
    "# Book Equity (BE) = Share Equity (se) - Prefered Stocks (ps) + Deferred Taxes (dt)\n",
    "compq['be'] = (compq['se']  # shareholder equity must be available, otherwise BE is missing\n",
    "               - compq['ps']  # preferred stock must be available, otherwise BE is missing\n",
    "               + compq['dt'].fillna(0))  # add deferred taxes if available\n",
    "               #- compa['prba'].fillna(0))  # subtract postretirement benefit assets if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COST = COGS + XSGA + XINT \n",
    "compq['cost'] = compq[['cogsq', 'xsgaq', 'xinty']].sum(axis=1, skipna=True)\n",
    "compq.loc[compq[['cogsq', 'xsgaq', 'xinty']].isnull().all(axis=1), 'cost'] = np.nan\n",
    "# OP = SALE - COST    \n",
    "compq['op'] = compq['saleq']-compq['cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output csv. format\n",
    "compq.to_csv(\"../Data/Raw/compustat_quarterly.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the dealscan syndicated loan data\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM tr_dealscan.dealscan\n",
    "    WHERE deal_active_date >= '{start_date}' AND deal_active_date <= '{end_date}'\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the data\n",
    "dealscan_data = db.raw_sql(query)\n",
    "# Save the data to a CSV file\n",
    "dealscan_data.to_csv('../Data/Raw/dealscan_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain Dealscan legacy lenders data (to use 2018 JF bank name link)\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM tr_dealscan.lendershares\n",
    "\"\"\"\n",
    "lendershares = db.raw_sql(query)\n",
    "\n",
    "# output csv. format\n",
    "lendershares.to_csv(\"../Data/Raw/lendershares.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disconnect from WRDS\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
